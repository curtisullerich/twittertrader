%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{hyperref}

\nocopyright
\frenchspacing
\pdfinfo{
/Title (Classification of Tweets by Company)
/Author (Curtis Ullerich, Daniel Stiner, Brandon Maxwell)}
\setcounter{secnumdepth}{0}  
\begin{document}

\title{Tweet Classification: Filtering \\ of Twitter for Company-relevant Tweets}
\author{
Curtis Ullerich, Daniel Stiner, Brandon Maxwell\\
Department of Computer Science and Engineering\\
Iowa State University
Ames, Iowa, USA\\
\{curtisu,stiner,bmaxwell\}@iastate.edu\\
}
\maketitle
\begin{abstract}
\begin{quote}
Twitter is a popular source for data mining due to its massive scale and inclusivity of current trends. As businesses seek to discover public opinion about their business or products, Twitter is one source for mining this information. Tweets present interesting classification challenges due to their irregular formatting and relatively small number of features. Tweet selection by keyword filtering often suffers from an high accuracy and low recall, or low accuracy and high recall. Using machine learning for text classification can improve this. We aim to survey a variety of text processing steps, focusing on the effects of tokenization, to increase accuracy of classification using a Naive Bayes classifier. We use a broad set of keywords with the goal of collecting a superset of the Tweets about a particular company (Apple, in this case) and train a binary classifier to filter out false positives.
\end{quote}
\end{abstract}

\section{Introduction}
Tweets are used as a source of data mining for applications ranging from predicting future stock price changes based on sentiment \cite{Ruiz:2012:CFT:2124295.2124358}, ... [ADD MORE]
In many cases, the problem of determining which tweets are relevant for a particular application is prerequisite to meaningful results. In some domains, filtering tweets based solely on keywords may be appropriate, but disambiguation remains an interest natural language processing problem in many cases. We present a system to disambiguate tweets about the company Apple.

\section{Related Work}
DUALIST is a system that extends Mallet by user-interactive feedback during training[Settles]. Included in their implementation was a TwitterPipe that performed some simple feature extraction. 
Part of the Sentiment Analysis Symposium focuses on tokenization of tweets for sentiment analysis, demonstrating that it provides consistent improvement over whitespace-based tokenizing \cite{potts2011}. A good deal of research has been done into sentiment classification of tweets, which requires very similar text processing and tokenization \cite{Pak10}. 

\section{Method}
\subsection{Corpus creation}
By accessing the Twitter "Firehose" stream through their public API, we harvested 115,000 tweets using broad keyword filters with the goal of collecting a superset of relevant tweets. This provides us a smaller set of features in the overall corpus. The keywords used for the company of choice during this round of testing, Apple, were collected manually from information on the company's website and the Wikipedia page about Apple:\\
...\\

This set of keywords clearly allows a large number of false positives:\\
nice fish and chip.. good pie apple :-) http://t.co/KVDN5r5l \\
20 chicken nuggets, chips, big mac, and a vanilla milkshake LIFE IS GOOD \\
1 more day whoop plus safari ride yay \\
Ashley staples an apple.  "AHHHH!!!!  Apple juice in my eye!" \\
I ain't seen uncle Mac in a while\\

We define a tweet to be "about" Apple if the tweet mentions the company (via direct reference or stock symbol), one of its products, or a service it offers. We make the assumption that spam will be filtered from the testing set. This could be done via an existing Naive Bayes classifier, but we simply did not include instances of spam in our corpus during the manual labeling process. We collected our tweets over the course of twelve hours. On Twitter, a single message posted is often reposted, or "re-tweeted," many more times in a very short timespan. Because of the small timespan of our data collection, a large number of retweets (effectively duplicates) appeared in the dataset. We filtered these duplicates out of the dataset as well to prevent over-fitting in our model. After filtering, our original set of 115,000 tweets was reduced to 65,000. A representative sample of non-spam, non-duplicate tweets has composition of 60\% topical instances and 40\% false positives [need to analyze this for sure].
A computer-posted spam tweet: I've collected 10,650 gold coins! http://t.co/H0V0O6yP \#ipad, \#ipadgames, \#gameinsight\\
A retweet, signified by "RT": RT @PHILerNotebook: Trying to fix my Mac. This gray loading bar takes 10 minutes to start up. Grr. Shall take it to an \_Apple\_ \_store\_ soon! \\

We hand labeled 2000 tweets for use in training and testing, including only English-language tweets in our training set. \\
Data sets and scripts used for processing text data are available on the project website.\\

\subsection{Preprocessing Pipeline}

We do all machine learning with the Mallet\cite{McCallumMALLET} library developed by the University of Massachusetts. Mallet includes abstractions for a data processing pipeline, during which we use both existing and custom processing "Pipes" to transform the data, beginning in our case with raw tweets text and ending in Mallet's internal FeatureVector format. We built several Pipes to analyze the effect of different filters and processes on the accuracy of classification. Not every Pipe proved to increase accuracy--some decreased it. We present the descriptions of and motivations for these Pipes here.

\subsubsection{Feature-space Enrichment}
Stopword removal: In order to improve accuracy of classification we decided to run each tweet through a pipe that would remove stopwords. Stopwords are generally known as adverbs, conjunctions, pronouns, and prepositions commonly found in English sentences, By removing these words, we hoped that the classifiers would be able to focus more on the relevant text and less on meaningless parts of the tweets. Since this is a common task for natural language processing we were able to make use of one of Mallet's stopwords pipes, using a default list of stopwords.
N-grams:
Fix emoticons:
HTML corrections: 
URL replacement:
Spell checking: Since twitter is an informal form of communication, we found that a fair number of tweets were being classified that had misspelled words. We decided that performing a spell check on the tweet might help the classifier work, since then it would only have to process proper English. In order to perform the spell check, we made use of an api that would return suggestions for misspelled words. Along with the suggested correct spellings of words, we were also given a "confidence" level for each suggestion. By using this value we were able to choose the best suggestion, and also filter out any suggestions that were too far from the original word.

\subsubsection{Disambiguation}
Lowercasing:
Stemming: Stemming is the process of reducing words to their "stem." While this stem does not necessarily have to be the root of the word, it should satisfy the property that related words have the same stem. Therefore the stem of the related words "argue," "argued," and "arguing" all have the stem of "argu," even though argu is not a real word. We believed that by reducing each word in the tweet to a its stem, we would be able to improve the classifying algorithm's ability to classify. In order to add stemming we made use of an api that used a Porter stemming algorithm to find the stem of each word.

\subsubsection{Tokenization}
Twitter data, and user-generated web content in general, provides unique challenges to an automatic tokenization system due to the high level of noise in the feature set [citation and more details]. Tweets are limited to 140 characters, which limits the total number of features possible. Some of the many natural language processing dilemmas present in tweets include excessive and irregular punctuation, frequent misspellings, emoticons, URLs, and hashtags, to name a few.

Cool ranch , 4 berry sundae , apple juice \#yessuh \#latenight \#snack http://t.co/ttc3vujp 
I just poured apple juice on my cereal.. Gah. \#SoTired 
I hate Siri.. -\_\_\_- 

We approach this problem using a layered token extraction system. Using regular expressions, we begin by searching for tokens that may include other, more general tokens. A prime example of this is an emoticon appearing in a URL.

Searching for emoticons in this tweet will extract :/ as an emoticon, effectively breaking up the URL.

Now on my iphone ?? http://t.co/Rqr1RL2R 

Additionally, users often include emoticons or links after text with no delimiting whitespace. 

I listen to my iPod every day and it's just broke omg:(!!

Extracting tokens using this layered approach eliminates many of these problems.

After tokenizing these special features in order (URLs, emoticons, usernames, and hashtags) we are left with a fragmented tweet containing myriad punctuation, capitalization, and creative spellings. As done by Potts (2011) we normalize the length of all letter sequences greater than two, as in English, these are invariably due to user-added emphasis, and condensing the larger set of tokens focuses the feature set. In the following tweet, "loooool" is normalized to "loool".

\#news can't wait for my signed \#OoRITE2OutNow it's emotional here right now loooool \#OoRITE2OutNow https://t.co/r4n4cn6C 

Note that such repetitions are often valid in URLs and some emoticons. Normalizing them prior to this step would make URLs invalid if using our link replacement Pipe.

As presented in our results, because of irregular capitalization, two tokens likely to be semantically identical with respect to company classification may be represented in multiple cases: {Nooo, NOOO, nooo, NoOo} is a prime example. To alleviate this, we attempt three different approaches. In the first, we simply lowercase all remaining tokens (note that many URLs become invalid after modifying case). In the second, we lowercase any text that is not in all caps. This serves to retain acronyms. In the third, we change all remaining tokens to lowercase, leaving the case of all strings containing "apple" (case insensitive) alone. We made this decision based on the semantic difference between the capitalization of Apple the company and apple the fruit. While correct capitalization is naturally not always present for this token, this is one case where capitalization serves to disambiguate. This same principle can be generalized to a larger set of keywords and applied to other companies in a similar fashion. 

\section{Experimental Setup}
...constant-size test set with sliced training
...comparison to n-fold validation

\section{Results}
...baseline using priors
  baseline using whitespace splitting in naive bayes.
  select interesting improvements.
  graphs of both validation types
  most useful features for classification

\section{Conclusion and Future Work}

Things that could be done....

[These guys] demonstrate a system of using background knowledge and relatedness, in which current information in the Twitter stream is used to more accurately estimate the priors for a Naive Bayes classification.

\section{Contributions}
We have built several reusable Java components that extend the Mallet API for processing of data from Twitter. We created a TweetJsonIterator that accepts a file of Twitter's JSON-formatted tweets and creates training Instances containing their values for easy processing during model training. We have implemented several Pipes that can be reused or easily modified to suit a similar Twitter processing purpose. These include FixEmoticons, Link2Title, Stemmer, SpellCheck, and Tokenize, which serves as a more extensible tokenizer than Mallet's default. All code is available through our project website. We also provide a corpus of 115,000 tweets selected by Apple-related keyword and our labeled data set of 2000 tweets. The bash scripts used to filter the data for near-duplicates and spam are also available for download.

\section{ Acknowledgments}
Thank you to Dr. Jin Tian and our TA Ru He for their guidance during this research project. We also extend our thanks to our friends for their help in manual labeling of tweets.

\section{References}
\begin{thebibliography}{99}
@article{potts2011,
    author    = "Christopher Potts",
    title     = "Sentiment Symposium Tutorial: Tokenizing",
    journal   = "",
    year      = "2011"
}
@inproceedings{Pak10,
  added-at = {2010-06-01T10:23:44.000+0200},
  address = {Valletta, Malta},
  author = {Pak, Alexander and Paroubek, Patrick},
  biburl = {http://www.bibsonomy.org/bibtex/25656c3bb1adf00c58a85e3204096961c/frederik},
  booktitle = {Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC'10)},
  date = {19-21},
  interhash = {ac930b0459a3c8a2fc2d74c52a475026},
  intrahash = {5656c3bb1adf00c58a85e3204096961c},
  isbn = {2-9517408-6-7},
  keywords = {imported},
  language = {english},
  month = may,
  publisher = {European Language Resources Association (ELRA)},
  timestamp = {2010-06-01T10:23:44.000+0200},
  title = {Twitter as a Corpus for Sentiment Analysis and Opinion Mining},
  url = {http://www.lrec-conf.org/proceedings/lrec2010/pdf/385\_Paper.pdf},
  year = 2010
}
@inproceedings{Ruiz:2012:CFT:2124295.2124358,
 author = {Ruiz, Eduardo J. and Hristidis, Vagelis and Castillo, Carlos and Gionis, Aristides and Jaimes, Alejandro},
 title = {Correlating financial time series with micro-blogging activity},
 booktitle = {Proceedings of the fifth ACM international conference on Web search and data mining},
 series = {WSDM '12},
 year = {2012},
 isbn = {978-1-4503-0747-5},
 location = {Seattle, Washington, USA},
 pages = {513--522},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2124295.2124358},
 doi = {10.1145/2124295.2124358},
 acmid = {2124358},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {financial time series, micro-blogging, social networks},
} 
@unpublished{McCallumMALLET,
    author = "Andrew Kachites McCallum",
    title = "MALLET: A Machine Learning for Language Toolkit",
    note = "http://mallet.cs.umass.edu",
    year = 2002,
}

\end{thebibliography}

[1] J. Bollen, H. Mao, and X.-J. Zeng. Twitter mood predicts the
stock market. Journal of Computational Science,
abs/1010.3003, 2010\\

\end{document}
